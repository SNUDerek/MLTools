{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# class-based picklable sentence indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/derek/anaconda3/envs/kerasCRF/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from mltools.preprocessing import Tokenizer, Indexer, Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test on toy data\n",
    "\n",
    "from the Aeneid:  http://classics.mit.edu/Virgil/aeneid.1.i.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [\n",
    "    'arms and the man i sing who forced by fate,',\n",
    "    \"and haughty Juno's unrelenting hate.\",\n",
    "    'expelled and exiled left the trojan shore,',\n",
    "    'long labors both by sea and land he bore.',\n",
    "    'and in the doubtful war before he won',\n",
    "    'the Latian realm and built the destined town.',\n",
    "    'his banished gods restored to rites divine',\n",
    "    'and settled sure succession in his line',\n",
    "    'from whence the race of Alban fathers come',\n",
    "    'and the long glories of majestic Rome.',\n",
    "    'O, muse, the causes and the crimes relate',\n",
    "    'what goddess was provoked and whence her hate',\n",
    "    'for what offense the queen of heaven began',\n",
    "    'to persecute so brave so just a man,',\n",
    "    'involved his anxious life in endless cares,',\n",
    "    'exposed to wants and hurried into wars?',\n",
    "    'can heavenly minds such high resentment show',\n",
    "    'or exercise their spite in human woe',\n",
    "    \"against the Tiber's mouth but far away\",\n",
    "    'an ancient town was seated on the sea',\n",
    "    'a Tyrian colony the people made',\n",
    "    'stout for the war and studious of their trade',\n",
    "    'carthage the name beloved by Juno more',\n",
    "    'than her own argos or the Samian shore',\n",
    "    'here stood her chariot here if heaven were kind',\n",
    "    'the seat of awful empire she designed',\n",
    "    'yet she had heard an ancient rumor fly',\n",
    "    'long cited by the people of the sky',\n",
    "    'that times to come should see the trojan race',\n",
    "    'her Carthage ruin and her towers deface',\n",
    "    'nor thus confined the yoke of sovreign sway',\n",
    "    'should on the necks of all the nations lay',\n",
    "    'she pondered this and feared it was in fate',\n",
    "    'nor could forget the war she waged of late',\n",
    "    'for conquring greece against the Trojan state.'\n",
    "]\n",
    "split_idx = int(len(text)*0.85)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test pipelining with `Tokenizer` and pickling model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(max_vocab=100, min_count=1, lower=True, regex=True)\n",
    "indicizer = Indexer(max_len=10, pad='post', truncate='post',\n",
    "                    reverse=False, unk_name='UNK', pad_name='PAD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('tokenize', tokenizer),\n",
    "    ('indicize', indicizer)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tokenize', Tokenizer(char=False, lower=True, max_vocab=100, min_count=1, regex=True,\n",
       "     stopwords=[], unk_name='UNK',\n",
       "     vcounts={'the': 20, 'and': 12, 'of': 6, 'by': 4, 'in': 4, 'to': 4, 'long': 3, 'his': 3, 'her': 3, 'man': 2, 'hate': 2, 'trojan': 2, 'shore': 2, 'sea': 2, 'he': 2, 'wa...mor': 141, 'fly': 142, 'cited': 143, 'sky': 144, 'that': 145, 'times': 146, 'UNK': 147, 'PAD': 0}))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(text[:split_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 34,   2,   1,  10,  35,  36,  37,  38,   4,  39],\n",
       "       [  2,  40,  41,  42,  11,   0,   0,   0,   0,   0],\n",
       "       [ 43,   2,  44,  45,   1,  12,  13,   0,   0,   0],\n",
       "       [  7,  46,  47,   4,  14,   2,  48,  15,  49,   0],\n",
       "       [  2,   5,   1,  50,  16,  51,  15,  52,   0,   0],\n",
       "       [  1,  53,  54,   2,  55,   1,  56,  17,   0,   0],\n",
       "       [  8,  57,  58,  59,   6,  60,  61,   0,   0,   0],\n",
       "       [  2,  62,  63,  64,   5,   8,  65,   0,   0,   0],\n",
       "       [ 66,  18,   1,  19,   3,  67,  68,  20,   0,   0],\n",
       "       [  2,   1,   7,  69,   3,  70,  71,   0,   0,   0],\n",
       "       [ 72,  73,   1,  74,   2,   1,  75,  76,   0,   0],\n",
       "       [ 21,  77,  22,  78,   2,  18,   9,  11,   0,   0],\n",
       "       [ 23,  21,  79,   1,  80,   3,  24,  81,   0,   0],\n",
       "       [  6,  82,  25,  83,  25,  84,  26,  10,   0,   0],\n",
       "       [ 85,   8,  86,  87,   5,  88,  89,   0,   0,   0],\n",
       "       [ 90,   6,  91,   2,  92,  93,  94,   0,   0,   0],\n",
       "       [ 95,  96,  97,  98,  99, 100, 101,   0,   0,   0],\n",
       "       [ 27, 102,  28, 103,   5, 104, 105,   0,   0,   0],\n",
       "       [106,   1, 107, 108, 109, 110, 111,   0,   0,   0],\n",
       "       [ 29,  30,  17,  22, 112, 113,   1,  14,   0,   0],\n",
       "       [ 26, 114, 115,   1,  31, 116,   0,   0,   0,   0],\n",
       "       [117,  23,   1,  16,   2, 118,   3,  28, 119,   0],\n",
       "       [120,   1, 121, 122,   4, 123, 124,   0,   0,   0],\n",
       "       [125,   9, 126, 127,  27,   1, 128,  13,   0,   0],\n",
       "       [ 32, 129,   9, 130,  32, 131,  24, 132, 133,   0],\n",
       "       [  1, 134,   3, 135, 136,  33, 137,   0,   0,   0],\n",
       "       [138,  33, 139, 140,  29,  30, 141, 142,   0,   0],\n",
       "       [  7, 143,   4,   1,  31,   3,   1, 144,   0,   0],\n",
       "       [145, 146,   6,  20, 147, 147,   1,  12,  19,   0]], dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vects = pipeline.transform(text[:split_idx])\n",
    "vects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arms and the man i sing who forced by fate\n",
      "and haughty junos unrelenting hate PAD PAD PAD PAD PAD\n",
      "expelled and exiled left the trojan shore PAD PAD PAD\n",
      "long labors both by sea and land he bore PAD\n",
      "and in the doubtful war before he won PAD PAD\n"
     ]
    }
   ],
   "source": [
    "texts = pipeline.inverse_transform(vects)\n",
    "for t in texts[:5]:\n",
    "    print(' '.join(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pickle, load pickle to new pipe and compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test-indexer.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(pipeline, 'test-indexer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_pipe = joblib.load('test-indexer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tokenizer(char=False, lower=True, max_vocab=100, min_count=1, regex=True,\n",
       "     stopwords=[], unk_name='UNK',\n",
       "     vcounts={'the': 20, 'and': 12, 'of': 6, 'by': 4, 'in': 4, 'to': 4, 'long': 3, 'his': 3, 'her': 3, 'man': 2, 'hate': 2, 'trojan': 2, 'shore': 2, 'sea': 2, 'he': 2, 'war': 2, 'town': 2, 'whence': 2, 'race': 2, 'come': 2, 'what': 2, 'was': 2, 'for': 2, 'heaven': 2, 'so': 2, 'a': 2, 'or': 2, 'their': 2,...heard': 1, 'rumor': 1, 'fly': 1, 'cited': 1, 'sky': 1, 'that': 1, 'times': 1, 'should': 1, 'see': 1})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_pipe.steps[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 34,   2,   1,  10,  35,  36,  37,  38,   4,  39],\n",
       "       [  2,  40,  41,  42,  11,   0,   0,   0,   0,   0],\n",
       "       [ 43,   2,  44,  45,   1,  12,  13,   0,   0,   0],\n",
       "       [  7,  46,  47,   4,  14,   2,  48,  15,  49,   0],\n",
       "       [  2,   5,   1,  50,  16,  51,  15,  52,   0,   0],\n",
       "       [  1,  53,  54,   2,  55,   1,  56,  17,   0,   0],\n",
       "       [  8,  57,  58,  59,   6,  60,  61,   0,   0,   0],\n",
       "       [  2,  62,  63,  64,   5,   8,  65,   0,   0,   0],\n",
       "       [ 66,  18,   1,  19,   3,  67,  68,  20,   0,   0],\n",
       "       [  2,   1,   7,  69,   3,  70,  71,   0,   0,   0],\n",
       "       [ 72,  73,   1,  74,   2,   1,  75,  76,   0,   0],\n",
       "       [ 21,  77,  22,  78,   2,  18,   9,  11,   0,   0],\n",
       "       [ 23,  21,  79,   1,  80,   3,  24,  81,   0,   0],\n",
       "       [  6,  82,  25,  83,  25,  84,  26,  10,   0,   0],\n",
       "       [ 85,   8,  86,  87,   5,  88,  89,   0,   0,   0],\n",
       "       [ 90,   6,  91,   2,  92,  93,  94,   0,   0,   0],\n",
       "       [ 95,  96,  97,  98,  99, 100, 101,   0,   0,   0],\n",
       "       [ 27, 102,  28, 103,   5, 104, 105,   0,   0,   0],\n",
       "       [106,   1, 107, 108, 109, 110, 111,   0,   0,   0],\n",
       "       [ 29,  30,  17,  22, 112, 113,   1,  14,   0,   0],\n",
       "       [ 26, 114, 115,   1,  31, 116,   0,   0,   0,   0],\n",
       "       [117,  23,   1,  16,   2, 118,   3,  28, 119,   0],\n",
       "       [120,   1, 121, 122,   4, 123, 124,   0,   0,   0],\n",
       "       [125,   9, 126, 127,  27,   1, 128,  13,   0,   0],\n",
       "       [ 32, 129,   9, 130,  32, 131,  24, 132, 133,   0],\n",
       "       [  1, 134,   3, 135, 136,  33, 137,   0,   0,   0],\n",
       "       [138,  33, 139, 140,  29,  30, 141, 142,   0,   0],\n",
       "       [  7, 143,   4,   1,  31,   3,   1, 144,   0,   0],\n",
       "       [145, 146,   6,  20, 147, 147,   1,  12,  19,   0]], dtype=int32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vects = loaded_pipe.transform(text[:split_idx])\n",
    "vects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kerasCRF",
   "language": "python",
   "name": "kerascrf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
