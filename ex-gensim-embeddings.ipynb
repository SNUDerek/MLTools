{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create custom word2vec embeddings\n",
    "\n",
    "use general domain data from the nltk Brown corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import brown\n",
    "from mltools.preprocessing import Tokenizer\n",
    "from mltools.embeddings import create_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read in tokenized text from brown and lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12403"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "browndata = brown.sents(categories=['news', 'editorial', 'reviews', 'government'])\n",
    "tokenizer = Tokenizer(lower=True, regex=True)\n",
    "browntoks = tokenizer.fit_transform(browndata)\n",
    "brownsents = [' '.join(s) for s in browntoks]\n",
    "len(brownsents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['the', 'fulton', 'county', 'grand', 'jury', 'said', 'friday', 'an', 'investigation', 'of', 'atlantas', 'recent', 'primary', 'election', 'produced', 'no', 'evidence', 'that', 'any', 'irregularities', 'took', 'place'], ['the', 'jury', 'further', 'said', 'in', 'termend', 'presentments', 'that', 'the', 'city', 'executive', 'committee', 'which', 'had', 'overall', 'charge', 'of', 'the', 'election', 'deserves', 'the', 'praise', 'and', 'thanks', 'of', 'the', 'city', 'of', 'atlanta', 'for', 'the', 'manner', 'in', 'which', 'the', 'election', 'was', 'conducted'], ['the', 'septemberoctober', 'term', 'jury', 'had', 'been', 'charged', 'by', 'fulton', 'superior', 'court', 'judge', 'durwood', 'pye', 'to', 'investigate', 'reports', 'of', 'possible', 'irregularities', 'in', 'the', 'hardfought', 'primary', 'which', 'was', 'won', 'by', 'mayornominate', 'ivan', 'allen', 'jr'], ['only', 'a', 'relative', 'handful', 'of', 'such', 'reports', 'was', 'received', 'the', 'jury', 'said', 'considering', 'the', 'widespread', 'interest', 'in', 'the', 'election', 'the', 'number', 'of', 'voters', 'and', 'the', 'size', 'of', 'this', 'city'], ['the', 'jury', 'said', 'it', 'did', 'find', 'that', 'many', 'of', 'georgias', 'registration', 'and', 'election', 'laws', 'are', 'outmoded', 'or', 'inadequate', 'and', 'often', 'ambiguous']]\n"
     ]
    }
   ],
   "source": [
    "print(browntoks[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence embeddings\n",
    "\n",
    "with open('sent_text.txt', 'w') as f:\n",
    "    for s in brownsents:\n",
    "        f.write(s)\n",
    "        f.write('\\n')\n",
    "\n",
    "w2v_vocab, w2v_model = create_embeddings('sent_text.txt',\n",
    "                       embeddings_path='text_embeddings.gensimmodel',\n",
    "                       vocab_path='text_mapping.json',\n",
    "                       min_count=2,\n",
    "                       workers=2,\n",
    "                       size = 200,\n",
    "                       iter=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('republican', 0.47915521264076233),\n",
       " ('committees', 0.45635107159614563),\n",
       " ('board', 0.4550314247608185),\n",
       " ('votes', 0.41035938262939453),\n",
       " ('caucus', 0.40127965807914734),\n",
       " ('senate', 0.3961509168148041),\n",
       " ('council', 0.3793870806694031),\n",
       " ('democraticendorsed', 0.3771839737892151),\n",
       " ('liberal', 0.3702690303325653),\n",
       " ('representatives', 0.3634282052516937)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.most_similar('committee')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('september', 0.6374590992927551),\n",
       " ('june', 0.5300639867782593),\n",
       " ('december', 0.526236355304718),\n",
       " ('1960', 0.5068605542182922),\n",
       " ('february', 0.503847599029541),\n",
       " ('november', 0.4959608316421509),\n",
       " ('january', 0.4883143901824951),\n",
       " ('1959', 0.48575159907341003),\n",
       " ('1951', 0.47862890362739563),\n",
       " ('1952', 0.47386273741722107)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.most_similar('october')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "core_eng",
   "language": "python",
   "name": "core_eng"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
